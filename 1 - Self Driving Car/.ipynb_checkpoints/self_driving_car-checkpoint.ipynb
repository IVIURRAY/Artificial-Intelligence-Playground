{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - ai.py and map.py are imported in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ai.py\n",
    "# AI for Self Driving Car\n",
    "\n",
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Creating the architecture of the Neural Network\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, nb_action):\n",
    "        super(Network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.nb_action = nb_action\n",
    "        self.fc1 = nn.Linear(input_size, 30)\n",
    "        self.fc2 = nn.Linear(30, nb_action)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        q_values = self.fc2(x)\n",
    "        return q_values\n",
    "\n",
    "# Implementing Experience Replay\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, event):\n",
    "        self.memory.append(event)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0]\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        samples = zip(*random.sample(self.memory, batch_size))\n",
    "        return map(lambda x: Variable(torch.cat(x, 0)), samples)\n",
    "\n",
    "# Implementing Deep Q Learning\n",
    "\n",
    "class Dqn():\n",
    "    \n",
    "    def __init__(self, input_size, nb_action, gamma):\n",
    "        self.gamma = gamma\n",
    "        self.reward_window = []\n",
    "        self.model = Network(input_size, nb_action)\n",
    "        self.memory = ReplayMemory(100000)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr = 0.001)\n",
    "        self.last_state = torch.Tensor(input_size).unsqueeze(0)\n",
    "        self.last_action = 0\n",
    "        self.last_reward = 0\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        probs = F.softmax(self.model(Variable(state, volatile = True))*100) # T=100\n",
    "        action = probs.multinomial()\n",
    "        return action.data[0,0]\n",
    "    \n",
    "    def learn(self, batch_state, batch_next_state, batch_reward, batch_action):\n",
    "        outputs = self.model(batch_state).gather(1, batch_action.unsqueeze(1)).squeeze(1)\n",
    "        next_outputs = self.model(batch_next_state).detach().max(1)[0]\n",
    "        target = self.gamma*next_outputs + batch_reward\n",
    "        td_loss = F.smooth_l1_loss(outputs, target)\n",
    "        self.optimizer.zero_grad()\n",
    "        td_loss.backward(retain_variables = True)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def update(self, reward, new_signal):\n",
    "        new_state = torch.Tensor(new_signal).float().unsqueeze(0)\n",
    "        self.memory.push((self.last_state, new_state, torch.LongTensor([int(self.last_action)]), torch.Tensor([self.last_reward])))\n",
    "        action = self.select_action(new_state)\n",
    "        if len(self.memory.memory) > 100:\n",
    "            batch_state, batch_next_state, batch_action, batch_reward = self.memory.sample(100)\n",
    "            self.learn(batch_state, batch_next_state, batch_reward, batch_action)\n",
    "        self.last_action = action\n",
    "        self.last_state = new_state\n",
    "        self.last_reward = reward\n",
    "        self.reward_window.append(reward)\n",
    "        if len(self.reward_window) > 1000:\n",
    "            del self.reward_window[0]\n",
    "        return action\n",
    "    \n",
    "    def score(self):\n",
    "        return sum(self.reward_window)/(len(self.reward_window)+1.)\n",
    "    \n",
    "    def save(self):\n",
    "        torch.save({'state_dict': self.model.state_dict(),\n",
    "                    'optimizer' : self.optimizer.state_dict(),\n",
    "                   }, 'last_brain.pth')\n",
    "    \n",
    "    def load(self):\n",
    "        if os.path.isfile('last_brain.pth'):\n",
    "            print(\"=> loading checkpoint... \")\n",
    "            checkpoint = torch.load('last_brain.pth')\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"done !\")\n",
    "        else:\n",
    "            print(\"no checkpoint found...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in /Users/Haydn/.kivy/logs/kivy_19-08-07_2.txt\n",
      "[INFO   ] [Kivy        ] v1.11.1\n",
      "[INFO   ] [Kivy        ] Installed at \"/Users/Haydn/Documents/Code/Jupyter/.venv/lib/python3.6/site-packages/kivy/__init__.py\"\n",
      "[INFO   ] [Python      ] v3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n",
      "[INFO   ] [Python      ] Interpreter at \"/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6\"\n",
      "[INFO   ] [Factory     ] 184 symbols loaded\n",
      "[INFO   ] [Image       ] Providers: img_tex, img_imageio, img_dds, img_sdl2, img_pil, img_gif (img_ffpyplayer ignored)\n",
      "[INFO   ] [Text        ] Provider: sdl2\n"
     ]
    }
   ],
   "source": [
    "# %load map.py\n",
    "# Self Driving Car\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "from random import random, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Importing the Kivy packages\n",
    "from kivy.app import App\n",
    "from kivy.uix.widget import Widget\n",
    "from kivy.uix.button import Button\n",
    "from kivy.graphics import Color, Ellipse, Line\n",
    "from kivy.config import Config\n",
    "from kivy.properties import NumericProperty, ReferenceListProperty, ObjectProperty\n",
    "from kivy.vector import Vector\n",
    "from kivy.clock import Clock\n",
    "\n",
    "# Importing the Dqn object from our AI in ai.py\n",
    "from ai import Dqn\n",
    "\n",
    "# Adding this line if we don't want the right click to put a red point\n",
    "Config.set('input', 'mouse', 'mouse,multitouch_on_demand')\n",
    "\n",
    "# Introducing last_x and last_y, used to keep the last point in memory when we draw the sand on the map\n",
    "last_x = 0\n",
    "last_y = 0\n",
    "n_points = 0\n",
    "length = 0\n",
    "\n",
    "# Getting our AI, which we call \"brain\", and that contains our neural network that represents our Q-function\n",
    "brain = Dqn(5,3,0.9)\n",
    "action2rotation = [0,20,-20]\n",
    "last_reward = 0\n",
    "scores = []\n",
    "\n",
    "# Initializing the map\n",
    "first_update = True\n",
    "def init():\n",
    "    global sand\n",
    "    global goal_x\n",
    "    global goal_y\n",
    "    global first_update\n",
    "    sand = np.zeros((longueur,largeur))\n",
    "    goal_x = 20\n",
    "    goal_y = largeur - 20\n",
    "    first_update = False\n",
    "\n",
    "# Initializing the last distance\n",
    "last_distance = 0\n",
    "\n",
    "# Creating the car class\n",
    "\n",
    "class Car(Widget):\n",
    "    \n",
    "    angle = NumericProperty(0)\n",
    "    rotation = NumericProperty(0)\n",
    "    velocity_x = NumericProperty(0)\n",
    "    velocity_y = NumericProperty(0)\n",
    "    velocity = ReferenceListProperty(velocity_x, velocity_y)\n",
    "    sensor1_x = NumericProperty(0)\n",
    "    sensor1_y = NumericProperty(0)\n",
    "    sensor1 = ReferenceListProperty(sensor1_x, sensor1_y)\n",
    "    sensor2_x = NumericProperty(0)\n",
    "    sensor2_y = NumericProperty(0)\n",
    "    sensor2 = ReferenceListProperty(sensor2_x, sensor2_y)\n",
    "    sensor3_x = NumericProperty(0)\n",
    "    sensor3_y = NumericProperty(0)\n",
    "    sensor3 = ReferenceListProperty(sensor3_x, sensor3_y)\n",
    "    signal1 = NumericProperty(0)\n",
    "    signal2 = NumericProperty(0)\n",
    "    signal3 = NumericProperty(0)\n",
    "\n",
    "    def move(self, rotation):\n",
    "        self.pos = Vector(*self.velocity) + self.pos\n",
    "        self.rotation = rotation\n",
    "        self.angle = self.angle + self.rotation\n",
    "        self.sensor1 = Vector(30, 0).rotate(self.angle) + self.pos\n",
    "        self.sensor2 = Vector(30, 0).rotate((self.angle+30)%360) + self.pos\n",
    "        self.sensor3 = Vector(30, 0).rotate((self.angle-30)%360) + self.pos\n",
    "        self.signal1 = int(np.sum(sand[int(self.sensor1_x)-10:int(self.sensor1_x)+10, int(self.sensor1_y)-10:int(self.sensor1_y)+10]))/400.\n",
    "        self.signal2 = int(np.sum(sand[int(self.sensor2_x)-10:int(self.sensor2_x)+10, int(self.sensor2_y)-10:int(self.sensor2_y)+10]))/400.\n",
    "        self.signal3 = int(np.sum(sand[int(self.sensor3_x)-10:int(self.sensor3_x)+10, int(self.sensor3_y)-10:int(self.sensor3_y)+10]))/400.\n",
    "        if self.sensor1_x>longueur-10 or self.sensor1_x<10 or self.sensor1_y>largeur-10 or self.sensor1_y<10:\n",
    "            self.signal1 = 1.\n",
    "        if self.sensor2_x>longueur-10 or self.sensor2_x<10 or self.sensor2_y>largeur-10 or self.sensor2_y<10:\n",
    "            self.signal2 = 1.\n",
    "        if self.sensor3_x>longueur-10 or self.sensor3_x<10 or self.sensor3_y>largeur-10 or self.sensor3_y<10:\n",
    "            self.signal3 = 1.\n",
    "\n",
    "class Ball1(Widget):\n",
    "    pass\n",
    "class Ball2(Widget):\n",
    "    pass\n",
    "class Ball3(Widget):\n",
    "    pass\n",
    "\n",
    "# Creating the game class\n",
    "\n",
    "class Game(Widget):\n",
    "\n",
    "    car = ObjectProperty(None)\n",
    "    ball1 = ObjectProperty(None)\n",
    "    ball2 = ObjectProperty(None)\n",
    "    ball3 = ObjectProperty(None)\n",
    "\n",
    "    def serve_car(self):\n",
    "        self.car.center = self.center\n",
    "        self.car.velocity = Vector(6, 0)\n",
    "\n",
    "    def update(self, dt):\n",
    "\n",
    "        global brain\n",
    "        global last_reward\n",
    "        global scores\n",
    "        global last_distance\n",
    "        global goal_x\n",
    "        global goal_y\n",
    "        global longueur\n",
    "        global largeur\n",
    "\n",
    "        longueur = self.width\n",
    "        largeur = self.height\n",
    "        if first_update:\n",
    "            init()\n",
    "\n",
    "        xx = goal_x - self.car.x\n",
    "        yy = goal_y - self.car.y\n",
    "        orientation = Vector(*self.car.velocity).angle((xx,yy))/180.\n",
    "        last_signal = [self.car.signal1, self.car.signal2, self.car.signal3, orientation, -orientation]\n",
    "        action = brain.update(last_reward, last_signal)\n",
    "        scores.append(brain.score())\n",
    "        rotation = action2rotation[action]\n",
    "        self.car.move(rotation)\n",
    "        distance = np.sqrt((self.car.x - goal_x)**2 + (self.car.y - goal_y)**2)\n",
    "        self.ball1.pos = self.car.sensor1\n",
    "        self.ball2.pos = self.car.sensor2\n",
    "        self.ball3.pos = self.car.sensor3\n",
    "\n",
    "        if sand[int(self.car.x),int(self.car.y)] > 0:\n",
    "            self.car.velocity = Vector(1, 0).rotate(self.car.angle)\n",
    "            last_reward = -1\n",
    "        else: # otherwise\n",
    "            self.car.velocity = Vector(6, 0).rotate(self.car.angle)\n",
    "            last_reward = -0.2\n",
    "            if distance < last_distance:\n",
    "                last_reward = 0.1\n",
    "\n",
    "        if self.car.x < 10:\n",
    "            self.car.x = 10\n",
    "            last_reward = -1\n",
    "        if self.car.x > self.width - 10:\n",
    "            self.car.x = self.width - 10\n",
    "            last_reward = -1\n",
    "        if self.car.y < 10:\n",
    "            self.car.y = 10\n",
    "            last_reward = -1\n",
    "        if self.car.y > self.height - 10:\n",
    "            self.car.y = self.height - 10\n",
    "            last_reward = -1\n",
    "\n",
    "        if distance < 100:\n",
    "            goal_x = self.width-goal_x\n",
    "            goal_y = self.height-goal_y\n",
    "        last_distance = distance\n",
    "\n",
    "# Adding the painting tools\n",
    "\n",
    "class MyPaintWidget(Widget):\n",
    "\n",
    "    def on_touch_down(self, touch):\n",
    "        global length, n_points, last_x, last_y\n",
    "        with self.canvas:\n",
    "            Color(0.8,0.7,0)\n",
    "            d = 10.\n",
    "            touch.ud['line'] = Line(points = (touch.x, touch.y), width = 10)\n",
    "            last_x = int(touch.x)\n",
    "            last_y = int(touch.y)\n",
    "            n_points = 0\n",
    "            length = 0\n",
    "            sand[int(touch.x),int(touch.y)] = 1\n",
    "\n",
    "    def on_touch_move(self, touch):\n",
    "        global length, n_points, last_x, last_y\n",
    "        if touch.button == 'left':\n",
    "            touch.ud['line'].points += [touch.x, touch.y]\n",
    "            x = int(touch.x)\n",
    "            y = int(touch.y)\n",
    "            length += np.sqrt(max((x - last_x)**2 + (y - last_y)**2, 2))\n",
    "            n_points += 1.\n",
    "            density = n_points/(length)\n",
    "            touch.ud['line'].width = int(20 * density + 1)\n",
    "            sand[int(touch.x) - 10 : int(touch.x) + 10, int(touch.y) - 10 : int(touch.y) + 10] = 1\n",
    "            last_x = x\n",
    "            last_y = y\n",
    "\n",
    "# Adding the API Buttons (clear, save and load)\n",
    "\n",
    "class CarApp(App):\n",
    "\n",
    "    def build(self):\n",
    "        parent = Game()\n",
    "        parent.serve_car()\n",
    "        Clock.schedule_interval(parent.update, 1.0/60.0)\n",
    "        self.painter = MyPaintWidget()\n",
    "        clearbtn = Button(text = 'clear')\n",
    "        savebtn = Button(text = 'save', pos = (parent.width, 0))\n",
    "        loadbtn = Button(text = 'load', pos = (2 * parent.width, 0))\n",
    "        clearbtn.bind(on_release = self.clear_canvas)\n",
    "        savebtn.bind(on_release = self.save)\n",
    "        loadbtn.bind(on_release = self.load)\n",
    "        parent.add_widget(self.painter)\n",
    "        parent.add_widget(clearbtn)\n",
    "        parent.add_widget(savebtn)\n",
    "        parent.add_widget(loadbtn)\n",
    "        return parent\n",
    "\n",
    "    def clear_canvas(self, obj):\n",
    "        global sand\n",
    "        self.painter.canvas.clear()\n",
    "        sand = np.zeros((longueur,largeur))\n",
    "\n",
    "    def save(self, obj):\n",
    "        print(\"saving brain...\")\n",
    "        brain.save()\n",
    "        plt.plot(scores)\n",
    "        plt.show()\n",
    "\n",
    "    def load(self, obj):\n",
    "        print(\"loading last saved brain...\")\n",
    "        brain.load()\n",
    "\n",
    "# Running the whole thing\n",
    "# if __name__ == '__main__':\n",
    "#     CarApp().run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
